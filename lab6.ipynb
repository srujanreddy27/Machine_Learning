{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNS+H/sVpcTB8mBrLWUZiTM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srujanreddy27/Machine_Learning/blob/main/lab6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAe-mZnv2V7m"
      },
      "outputs": [],
      "source": [
        "#A1\n",
        "import math\n",
        "\n",
        "def summation_unit(inputs, weights):\n",
        "    return sum(i * w for i, w in zip(inputs, weights))\n",
        "\n",
        "def step_function(x):\n",
        "    return 1 if x >= 0 else 0\n",
        "\n",
        "def bipolar_step_function(x):\n",
        "    return 1 if x >= 0 else -1\n",
        "\n",
        "def sigmoid_function(x):\n",
        "    return 1 / (1 + math.exp(-x))\n",
        "\n",
        "def tanh_function(x):\n",
        "    return math.tanh(x)\n",
        "\n",
        "def relu_function(x):\n",
        "    return max(0, x)\n",
        "\n",
        "def leaky_relu_function(x):\n",
        "    return x if x >= 0 else 0.01 * x\n",
        "\n",
        "def comparator_unit(predicted, actual):\n",
        "    return actual - predicted\n",
        "\n",
        "#A2\n",
        "def train_perceptron_and_gate(inputs, outputs, epochs=1000, lr=0.05):\n",
        "    weights = [10, 0.2, -0.75]\n",
        "    for epoch in range(epochs):\n",
        "        total_error = 0\n",
        "        for i in range(len(inputs)):\n",
        "            summation = summation_unit([1] + inputs[i], weights)\n",
        "            prediction = step_function(summation)\n",
        "            error = comparator_unit(prediction, outputs[i])\n",
        "            total_error += error ** 2\n",
        "            for j in range(len(weights)):\n",
        "                weights[j] += lr * error * ([1] + inputs[i])[j]\n",
        "        if total_error <= 0.002:\n",
        "            break\n",
        "    return weights, epoch\n",
        "\n",
        "inputs = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
        "outputs = [0, 0, 0, 1]\n",
        "weights, epochs = train_perceptron_and_gate(inputs, outputs)\n",
        "\n",
        "#A3\n",
        "def train_with_activation(inputs, outputs, activation_func, epochs=1000, lr=0.05):\n",
        "    weights = [10, 0.2, -0.75]\n",
        "    for epoch in range(epochs):\n",
        "        total_error = 0\n",
        "        for i in range(len(inputs)):\n",
        "            summation = summation_unit([1] + inputs[i], weights)\n",
        "            prediction = activation_func(summation)\n",
        "            error = comparator_unit(prediction, outputs[i])\n",
        "            total_error += error ** 2\n",
        "            for j in range(len(weights)):\n",
        "                weights[j] += lr * error * ([1] + inputs[i])[j]\n",
        "        if total_error <= 0.002:\n",
        "            break\n",
        "    return weights, epoch\n",
        "\n",
        "# Example using Sigmoid Function\n",
        "weights, epochs = train_with_activation(inputs, outputs, sigmoid_function)\n",
        "\n",
        "#A4\n",
        "learning_rates = [0.1 * i for i in range(1, 11)]\n",
        "iterations = []\n",
        "\n",
        "for lr in learning_rates:\n",
        "    _, epoch = train_perceptron_and_gate(inputs, outputs, lr=lr)\n",
        "    iterations.append(epoch)\n",
        "\n",
        "#A5\n",
        "inputs_xor = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
        "outputs_xor = [0, 1, 1, 0]\n",
        "weights, epochs = train_perceptron_and_gate(inputs_xor, outputs_xor)\n",
        "\n",
        "#A6\n",
        "def train_perceptron_customers(data, labels, epochs=1000, lr=0.05):\n",
        "    weights = [0.1, 0.2, 0.3, 0.4]  # Example initial weights\n",
        "    for epoch in range(epochs):\n",
        "        total_error = 0\n",
        "        for i in range(len(data)):\n",
        "            summation = summation_unit([1] + data[i], weights)\n",
        "            prediction = sigmoid_function(summation)\n",
        "            error = comparator_unit(prediction, labels[i])\n",
        "            total_error += error ** 2\n",
        "            for j in range(len(weights)):\n",
        "                weights[j] += lr * error * ([1] + data[i])[j]\n",
        "        if total_error <= 0.002:\n",
        "            break\n",
        "    return weights, epoch\n",
        "\n",
        "customer_data = [\n",
        "    [20, 6, 2],\n",
        "    [16, 3, 6],\n",
        "    [27, 6, 2],\n",
        "    [19, 1, 2],\n",
        "    [24, 4, 2],\n",
        "    [22, 1, 5],\n",
        "    [15, 4, 2],\n",
        "    [18, 4, 2],\n",
        "    [21, 1, 4],\n",
        "    [16, 2, 4]\n",
        "]\n",
        "\n",
        "high_value_labels = [1, 1, 1, 0, 1, 0, 1, 1, 0, 0]\n",
        "\n",
        "weights, epochs = train_perceptron_customers(customer_data, high_value_labels)\n",
        "\n",
        "#A7\n",
        "import numpy as np\n",
        "\n",
        "def pseudo_inverse_solution(data, labels):\n",
        "    X = np.array([[1] + d for d in data])\n",
        "    Y = np.array(labels)\n",
        "    pseudo_inv = np.linalg.pinv(X)\n",
        "    weights = np.dot(pseudo_inv, Y)\n",
        "    return weights\n",
        "\n",
        "weights_pseudo = pseudo_inverse_solution(customer_data, high_value_labels)\n",
        "\n",
        "#A8\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "def train_nn_and_gate(inputs, outputs, epochs=1000, lr=0.05):\n",
        "    weights_input_hidden = [0.5, -0.6, 0.2]\n",
        "    weights_hidden_output = [0.4, -0.7]\n",
        "    for epoch in range(epochs):\n",
        "        total_error = 0\n",
        "        for i in range(len(inputs)):\n",
        "            hidden_input = summation_unit([1] + inputs[i], weights_input_hidden)\n",
        "            hidden_output = sigmoid_function(hidden_input)\n",
        "            output_input = summation_unit([1, hidden_output], weights_hidden_output)\n",
        "            output = sigmoid_function(output_input)\n",
        "            error = comparator_unit(output, outputs[i])\n",
        "            total_error += error ** 2\n",
        "            delta_output = error * sigmoid_derivative(output)\n",
        "            delta_hidden = delta_output * sigmoid_derivative(hidden_output) * weights_hidden_output[1]\n",
        "            weights_hidden_output[0] += lr * delta_output * 1\n",
        "            weights_hidden_output[1] += lr * delta_output * hidden_output\n",
        "            for j in range(len(weights_input_hidden)):\n",
        "                weights_input_hidden[j] += lr * delta_hidden * ([1] + inputs[i])[j]\n",
        "        if total_error <= 0.002:\n",
        "            break\n",
        "    return weights_input_hidden, weights_hidden_output, epoch\n",
        "\n",
        "weights_input_hidden, weights_hidden_output, epochs = train_nn_and_gate(inputs, outputs)\n",
        "\n",
        "#A9\n",
        "weights_input_hidden, weights_hidden_output, epochs = train_nn_and_gate(inputs_xor, outputs_xor)\n",
        "\n",
        "#A10\n",
        "def train_perceptron_2_outputs(inputs, outputs, epochs=1000, lr=0.05):\n",
        "    weights = [[0.1, 0.2, -0.1], [0.05, 0.3, -0.25]]\n",
        "    for epoch in range(epochs):\n",
        "        total_error = 0\n",
        "        for i in range(len(inputs)):\n",
        "            summation_1 = summation_unit([1] + inputs[i], weights[0])\n",
        "            summation_2 = summation_unit([1] + inputs[i], weights[1])\n",
        "            prediction_1 = step_function(summation_1)\n",
        "            prediction_2 = step_function(summation_2)\n",
        "            error_1 = comparator_unit(prediction_1, outputs[i][0])\n",
        "            error_2 = comparator_unit(prediction_2, outputs[i][1])\n",
        "            total_error += error_1 ** 2 + error_2 ** 2\n",
        "            for j in range(len(weights[0])):\n",
        "                weights[0][j] += lr * error_1 * ([1] + inputs[i])[j]\n",
        "                weights[1][j] += lr * error_2 * ([1] + inputs[i])[j]\n",
        "        if total_error <= 0.002:\n",
        "            break\n",
        "    return weights, epoch\n",
        "\n",
        "outputs_2 = [[1, 0], [1, 0], [1, 0], [0, 1]]  # Example for AND Gate logic\n",
        "weights, epochs = train_perceptron_2_outputs(inputs, outputs_2)\n",
        "\n",
        "#A11\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# AND Gate using MLPClassifier\n",
        "mlp_and = MLPClassifier(hidden_layer_sizes=(), activation='logistic', solver='sgd', max_iter=1000)\n",
        "mlp_and.fit(inputs, outputs)\n",
        "and_predictions = mlp_and.predict(inputs)\n",
        "\n",
        "# XOR Gate using MLPClassifier\n",
        "mlp_xor = MLPClassifier(hidden_layer_sizes=(), activation='logistic', solver='sgd', max_iter=1000)\n",
        "mlp_xor.fit(inputs_xor, outputs_xor)\n",
        "xor_predictions = mlp_xor.predict(inputs_xor)\n",
        "\n",
        "#A12\n",
        "mlp_project = MLPClassifier(hidden_layer_sizes=(5,), activation='logistic', solver='sgd', max_iter=1000)\n",
        "mlp_project.fit(customer_data, high_value_labels)\n",
        "project_predictions = mlp_project.predict(customer_data)"
      ]
    }
  ]
}